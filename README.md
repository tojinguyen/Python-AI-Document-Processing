# Python AI Document Processing System

A comprehensive AI-powered document processing system that allows users to upload, process, and interact with their documents through an intelligent chatbot interface.

## üéØ Project Overview

This system enables users to upload documents (PDF, DOCX, TXT), automatically processes them using AI to extract and vectorize content, and provides an intelligent chatbot interface for document querying and information retrieval.

## üèóÔ∏è System Architecture

### Tech Stack
- **Backend**: Django REST Framework
- **Database**: PostgreSQL with pgvector extension
- **File Storage**: MinIO (S3-compatible)
- **Message Queue**: RabbitMQ + Celery
- **AI/ML**: HuggingFace Transformers / OpenAI API
- **Authentication**: JWT tokens
- **Vector Database**: pgvector for similarity search

### Key Components
1. **User Management Module** - Registration, authentication, and access control
2. **Document Management Module** - Upload, storage, and processing pipeline
3. **Chatbot Module** - AI-powered document querying
4. **Admin Module** - System monitoring and management (optional)

---

## üìã Module Details

## **1. Module User (ƒêƒÉng k√Ω / Qu·∫£n l√Ω t√†i kho·∫£n)**

> **M·ª•c ti√™u**: Qu·∫£n l√Ω user v√† b·∫£o m·∫≠t quy·ªÅn truy c·∫≠p d·ªØ li·ªáu t√†i li·ªáu.

### **T√≠nh nƒÉng:**

#### **ƒêƒÉng k√Ω t√†i kho·∫£n**
- ƒêƒÉng k√Ω v·ªõi email v√† m·∫≠t kh·∫©u
- X√°c th·ª±c c∆° b·∫£n v·ªõi Django authentication
- Hash password b·∫±ng Django's built-in security

#### **ƒêƒÉng nh·∫≠p**
- X√°c th·ª±c user credentials
- Tr·∫£ v·ªÅ JWT token cho session management
- Token refresh mechanism

#### **Profile c√° nh√¢n**
- Xem th√¥ng tin c√° nh√¢n (email, t√™n, ng√†y t·∫°o t√†i kho·∫£n)
- Ch·ªânh s·ª≠a th√¥ng tin c√° nh√¢n
- ƒê·ªïi m·∫≠t kh·∫©u

#### **Ph√¢n quy·ªÅn c∆° b·∫£n**
- M·ªói user ch·ªâ c√≥ th·ªÉ:
  - Xem t√†i li·ªáu c·ªßa ch√≠nh m√¨nh
  - Chat v·ªõi t√†i li·ªáu c·ªßa ch√≠nh m√¨nh
  - Kh√¥ng th·ªÉ truy c·∫≠p d·ªØ li·ªáu c·ªßa user kh√°c

### **API Endpoints:**
```
POST /api/auth/register/     # ƒêƒÉng k√Ω t√†i kho·∫£n
POST /api/auth/login/        # ƒêƒÉng nh·∫≠p
POST /api/auth/refresh/      # Refresh token
GET  /api/auth/profile/      # Xem profile
PUT  /api/auth/profile/      # C·∫≠p nh·∫≠t profile
POST /api/auth/change-password/  # ƒê·ªïi m·∫≠t kh·∫©u
```

---

## **2. Module Document (Qu·∫£n l√Ω t√†i li·ªáu)**

> **M·ª•c ti√™u**: Upload, l∆∞u tr·ªØ, v√† x·ª≠ l√Ω t√†i li·ªáu ƒë·ªÉ tra c·ª©u.

### **2.1. Upload & Storage**

#### **File Upload Process**
- User upload t√†i li·ªáu qua web interface
- H·ªó tr·ª£ ƒë·ªãnh d·∫°ng: PDF, DOCX, TXT
- Ki·ªÉm tra ƒë·ªãnh d·∫°ng v√† k√≠ch th∆∞·ªõc file
- L∆∞u file g·ªëc v√†o **MinIO** storage

#### **Database Schema**
L∆∞u metadata v√†o **PostgreSQL**:

```sql
-- Documents table
CREATE TABLE documents (
    document_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id),
    file_name VARCHAR(255) NOT NULL,
    file_path VARCHAR(500) NOT NULL,
    file_size BIGINT,
    mime_type VARCHAR(100),
    status VARCHAR(20) DEFAULT 'pending',
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Status values: pending, processing, ready, failed
```

### **2.2. X·ª≠ l√Ω t√†i li·ªáu (Background Task v·ªõi Celery + RabbitMQ)**

> **Khi upload xong, h·ªá th·ªëng s·∫Ω ch·∫°y job n·ªÅn ƒë·ªÉ ph√¢n t√≠ch d·ªØ li·ªáu.**

#### **Processing Pipeline:**

1. **Extract Text**
   - S·ª≠ d·ª•ng `PyMuPDF` cho PDF files
   - S·ª≠ d·ª•ng `python-docx` cho DOCX files
   - ƒê·ªçc tr·ª±c ti·∫øp cho TXT files
   - L∆∞u extracted text v√†o database

2. **Text Chunking**
   - C·∫Øt t√†i li·ªáu th√†nh c√°c ƒëo·∫°n nh·ªè (~500 t·ª´)
   - Overlap gi·ªØa c√°c chunks ƒë·ªÉ ƒë·∫£m b·∫£o context
   - L∆∞u chunks v√†o b·∫£ng `document_chunks`

3. **Embedding Generation**
   - Convert t·ª´ng chunk th√†nh vector embedding
   - S·ª≠ d·ª•ng HuggingFace Sentence Transformers ho·∫∑c OpenAI API
   - Vector dimension: 768 ho·∫∑c 1536 (t√πy model)

4. **Vector Storage**
   - L∆∞u vectors v√†o PostgreSQL v·ªõi pgvector extension
   - T·∫°o index cho similarity search
   - Link chunks v·ªõi document g·ªëc

5. **Status Update**
   - C·∫≠p nh·∫≠t `status = 'ready'` khi ho√†n th√†nh
   - `status = 'failed'` n·∫øu c√≥ l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω

#### **Database Schema cho Chunks:**

```sql
-- Document chunks table
CREATE TABLE document_chunks (
    chunk_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    document_id UUID REFERENCES documents(document_id),
    chunk_index INTEGER,
    content TEXT NOT NULL,
    embedding VECTOR(768), -- pgvector type
    page_number INTEGER,
    created_at TIMESTAMP DEFAULT NOW()
);

-- Create index for similarity search
CREATE INDEX ON document_chunks USING ivfflat (embedding vector_cosine_ops);
```

#### **Celery Task Benefits:**
- Job ch·∫°y background, kh√¥ng block UI
- C√≥ th·ªÉ scale workers khi traffic cao
- Retry mechanism khi task fail
- Task monitoring v√† logging

### **API Endpoints:**
```
POST /api/documents/upload/           # Upload t√†i li·ªáu
GET  /api/documents/                  # List t√†i li·ªáu c·ªßa user
GET  /api/documents/{id}/            # Chi ti·∫øt t√†i li·ªáu
DELETE /api/documents/{id}/          # X√≥a t√†i li·ªáu
GET  /api/documents/{id}/status/     # Check processing status
```

---

## **3. Module Chatbot (Tra c·ª©u t√†i li·ªáu)**

> **M·ª•c ti√™u**: Cho ph√©p user chat v·ªõi h·ªá th·ªëng ƒë·ªÉ t√¨m th√¥ng tin t·ª´ t√†i li·ªáu ƒë√£ upload.

### **3.1. Chat Flow**

#### **Query Processing Pipeline:**

1. **User Input**: User nh·∫≠p c√¢u h·ªèi trong chat interface
2. **Query Embedding**: Convert c√¢u h·ªèi th√†nh vector embedding
3. **Similarity Search**: 
   - T√¨m top N chunks c√≥ embedding g·∫ßn nh·∫•t
   - Ch·ªâ search trong documents c·ªßa user hi·ªán t·∫°i
   - S·ª≠ d·ª•ng cosine similarity
4. **Context Preparation**: Chu·∫©n b·ªã context t·ª´ relevant chunks
5. **LLM Processing**: G·ª≠i context + question t·ªõi LLM
6. **Response Generation**: AI t·∫°o c√¢u tr·∫£ l·ªùi d·ª±a tr√™n context
7. **Source Attribution**: Attach th√¥ng tin ngu·ªìn t√†i li·ªáu

#### **Similarity Search Query:**
```sql
SELECT 
    dc.chunk_id,
    dc.content,
    dc.page_number,
    d.file_name,
    1 - (dc.embedding <=> %s) as similarity_score
FROM document_chunks dc
JOIN documents d ON dc.document_id = d.document_id
WHERE d.user_id = %s 
  AND d.status = 'ready'
ORDER BY dc.embedding <=> %s
LIMIT %s;
```

### **3.2. Chat API Response**

#### **Response Format:**

```json
{
  "conversation_id": "uuid-string",
  "question": "ƒêi·ªÅu kho·∫£n v·ªÅ ngh·ªâ vi·ªác trong h·ª£p ƒë·ªìng l√† g√¨?",
  "answer": "Theo ƒêi·ªÅu 12 trong h·ª£p ƒë·ªìng lao ƒë·ªông, nh√¢n vi√™n c√≥ quy·ªÅn ngh·ªâ vi·ªác v·ªõi ƒëi·ªÅu ki·ªán th√¥ng b√°o tr∆∞·ªõc √≠t nh·∫•t 30 ng√†y l√†m vi·ªác. Nh√¢n vi√™n c·∫ßn n·ªôp ƒë∆°n xin ngh·ªâ vi·ªác theo m·∫´u quy ƒë·ªãnh v√† ho√†n th√†nh b√†n giao c√¥ng vi·ªác.",
  "sources": [
    {
      "chunk_id": "uuid-15",
      "document_id": "uuid-doc-1",
      "document_name": "HopDongLaoDong2025.pdf",
      "page_number": 3,
      "content_preview": "ƒêi·ªÅu 12: Quy ƒë·ªãnh v·ªÅ ngh·ªâ vi·ªác. Nh√¢n vi√™n c√≥ quy·ªÅn ƒë∆°n ph∆∞∆°ng ch·∫•m d·ª©t h·ª£p ƒë·ªìng lao ƒë·ªông v·ªõi ƒëi·ªÅu ki·ªán th√¥ng b√°o tr∆∞·ªõc...",
      "similarity_score": 0.89
    },
    {
      "chunk_id": "uuid-27",
      "document_id": "uuid-doc-1", 
      "document_name": "HopDongLaoDong2025.pdf",
      "page_number": 4,
      "content_preview": "Quy tr√¨nh b√†n giao: Nh√¢n vi√™n ngh·ªâ vi·ªác ph·∫£i ho√†n th√†nh vi·ªác b√†n giao t√†i li·ªáu, d·ª± √°n v√† t√†i s·∫£n c√¥ng ty...",
      "similarity_score": 0.76
    }
  ],
  "timestamp": "2025-09-18T10:30:00Z"
}
```

### **3.3. UI Chatbot Features**

#### **Chat Interface:**
- **Modern chat UI** gi·ªëng ChatGPT/Claude
- **Real-time messaging** v·ªõi WebSocket ho·∫∑c polling
- **Message history** l∆∞u conversation
- **Typing indicators** khi AI ƒëang process

#### **Source Citations:**
- M·ªói response c√≥ **tr√≠ch d·∫´n ngu·ªìn r√µ r√†ng**
- Click v√†o citation ƒë·ªÉ xem **full context** c·ªßa chunk
- Highlight text t∆∞∆°ng ·ª©ng trong document g·ªëc
- **Page number reference** ƒë·ªÉ d·ªÖ t√¨m trong file g·ªëc

#### **Enhanced Features:**
- **Conversation threads** - group related questions
- **Quick suggestions** based on document content
- **Export chat history** to PDF/text
- **Search in chat history**

### **API Endpoints:**
```
POST /api/chat/ask/                    # G·ª≠i c√¢u h·ªèi
GET  /api/chat/conversations/          # List conversations
GET  /api/chat/conversations/{id}/     # Chi ti·∫øt conversation
POST /api/chat/conversations/          # T·∫°o conversation m·ªõi
DELETE /api/chat/conversations/{id}/   # X√≥a conversation
GET  /api/chat/chunks/{id}/           # Xem full context c·ªßa chunk
```

---

## **4. Module Admin (Optional)**

> **Gi√∫p qu·∫£n l√Ω h·ªá th·ªëng n·ªôi b·ªô khi c√≥ th·ªùi gian ph√°t tri·ªÉn th√™m.**

### **4.1. User Management**
- **User List**: Xem danh s√°ch t·∫•t c·∫£ users
- **User Details**: Th√¥ng tin chi ti·∫øt v√† activity logs
- **User Actions**: Block/unblock, reset password
- **User Statistics**: Document count, chat activity

### **4.2. System Analytics**
- **Document Statistics**:
  - T·ªïng s·ªë documents ƒë√£ upload
  - Documents by status (pending/processing/ready/failed)
  - Storage usage statistics
  - Most active users

- **Chat Analytics**:
  - Top c√¢u h·ªèi ph·ªï bi·∫øn
  - Response accuracy metrics
  - User engagement metrics
  - Peak usage times

### **4.3. System Monitoring**
- **Celery Task Monitor**:
  - Active/pending/failed tasks
  - Task execution times
  - Worker status and health
  - Queue depth monitoring

- **System Health**:
  - Database performance metrics
  - MinIO storage status
  - API response times
  - Error rate monitoring

### **Admin API Endpoints:**
```
GET  /api/admin/users/                 # User management
GET  /api/admin/stats/documents/       # Document statistics  
GET  /api/admin/stats/chat/           # Chat analytics
GET  /api/admin/system/health/        # System health check
GET  /api/admin/celery/tasks/         # Celery task monitoring
```

---

## üöÄ Getting Started

### **Prerequisites**
- Python 3.9+
- PostgreSQL 13+ with pgvector extension
- Redis (for Celery)
- RabbitMQ (message broker)
- MinIO or AWS S3 access

### **Installation**

1. **Clone repository**
```bash
git clone https://github.com/tojinguyen/Python-AI-Document-Processing.git
cd Python-AI-Document-Processing
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Setup PostgreSQL with pgvector**
```sql
CREATE EXTENSION vector;
```

5. **Environment configuration**
```bash
cp .env.example .env
# Edit .env with your configurations
```

6. **Database migration**
```bash
python manage.py migrate
```

7. **Start services**
```bash
# Start Celery worker
celery -A config worker -l info

# Start Django development server  
python manage.py runserver
```

### **Environment Variables**
```env
# Database
DATABASE_URL=postgresql://user:password@localhost:5432/doc_processing

# MinIO/S3
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=your_access_key
MINIO_SECRET_KEY=your_secret_key

# AI/ML
OPENAI_API_KEY=your_openai_key
HUGGINGFACE_API_KEY=your_hf_key

# Celery
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# JWT
JWT_SECRET_KEY=your_jwt_secret
```

---

## üìä Database Schema

### **Core Tables**
```sql
-- Users table (Django default extended)
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    password VARCHAR(128) NOT NULL,
    first_name VARCHAR(150),
    last_name VARCHAR(150),
    is_active BOOLEAN DEFAULT TRUE,
    date_joined TIMESTAMP DEFAULT NOW()
);

-- Documents table
CREATE TABLE documents (
    document_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    file_name VARCHAR(255) NOT NULL,
    file_path VARCHAR(500) NOT NULL,
    file_size BIGINT,
    mime_type VARCHAR(100),
    status VARCHAR(20) DEFAULT 'pending',
    processing_error TEXT,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Document chunks with vectors
CREATE TABLE document_chunks (
    chunk_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    document_id UUID REFERENCES documents(document_id) ON DELETE CASCADE,
    chunk_index INTEGER NOT NULL,
    content TEXT NOT NULL,
    embedding VECTOR(768),
    page_number INTEGER,
    token_count INTEGER,
    created_at TIMESTAMP DEFAULT NOW()
);

-- Chat conversations
CREATE TABLE conversations (
    conversation_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    title VARCHAR(255),
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Chat messages
CREATE TABLE chat_messages (
    message_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    conversation_id UUID REFERENCES conversations(conversation_id) ON DELETE CASCADE,
    role VARCHAR(20) NOT NULL, -- 'user' or 'assistant'
    content TEXT NOT NULL,
    sources JSONB, -- Referenced chunks and documents
    created_at TIMESTAMP DEFAULT NOW()
);
```

---

## üîß API Documentation

### **Authentication Flow**
```python
# Register
POST /api/auth/register/
{
    "email": "user@example.com",
    "password": "securepassword",
    "first_name": "John",
    "last_name": "Doe"
}

# Login Response
{
    "access_token": "jwt_access_token",
    "refresh_token": "jwt_refresh_token",
    "user": {
        "id": "uuid",
        "email": "user@example.com",
        "first_name": "John"
    }
}
```

### **Document Upload Flow**
```python
# Upload document
POST /api/documents/upload/
Content-Type: multipart/form-data
Authorization: Bearer {access_token}

{
    "file": file_object,
    "title": "Optional custom title"
}

# Response
{
    "document_id": "uuid",
    "file_name": "document.pdf", 
    "status": "pending",
    "message": "Document uploaded successfully. Processing will begin shortly."
}
```

### **Chat Flow**
```python
# Start conversation
POST /api/chat/ask/
Authorization: Bearer {access_token}

{
    "question": "What are the vacation policies?",
    "conversation_id": "optional_uuid" // omit to start new conversation
}

# Response format shown in section 3.2 above
```

---

## üèÉ‚Äç‚ôÇÔ∏è Development Workflow

### **Adding New Features**
1. Create feature branch from `main`
2. Implement backend API endpoints
3. Add database migrations if needed  
4. Write unit tests
5. Update API documentation
6. Create pull request

### **Testing**
```bash
# Run all tests
python manage.py test

# Run specific app tests
python manage.py test apps.documents.tests

# Coverage report
coverage run manage.py test
coverage report
```

### **Code Quality**
```bash
# Format code
black .
isort .

# Lint code  
flake8 .
pylint apps/
```

---

## üìà Performance Considerations

### **Optimization Strategies**
- **Database Indexing**: Proper indexes on user_id, document_id, embedding vectors
- **Caching**: Redis cache for frequent queries and user sessions
- **Async Processing**: All heavy operations via Celery background tasks
- **Pagination**: All list endpoints support pagination
- **File Compression**: Compress stored files when possible

### **Scaling Recommendations**
- **Horizontal Scaling**: Multiple Celery workers for document processing
- **Database Replication**: Read replicas for analytics queries
- **CDN Integration**: Serve static files via CDN
- **Load Balancing**: Multiple Django app instances behind load balancer

---

## üîí Security Features

### **Authentication & Authorization**
- JWT token-based authentication
- User isolation - can only access own documents
- Password hashing with Django's PBKDF2
- Token expiration and refresh mechanism

### **Data Protection**
- Input validation and sanitization
- SQL injection prevention with ORM
- File type validation for uploads
- Rate limiting on API endpoints

### **Infrastructure Security**
- Environment variable configuration
- Secrets management for API keys
- HTTPS enforcement in production
- Database connection encryption

---

## üöÄ Deployment Guide

### **Production Environment**
```yaml
# docker-compose.yml example
version: '3.8'
services:
  web:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://...
      - REDIS_URL=redis://...
    depends_on:
      - db
      - redis
      
  worker:
    build: .
    command: celery -A config worker -l info
    depends_on:
      - db
      - redis
      
  db:
    image: pgvector/pgvector:pg15
    environment:
      POSTGRES_DB: doc_processing
      
  redis:
    image: redis:7-alpine
```

### **Environment Setup**
1. Set up PostgreSQL with pgvector
2. Configure MinIO or S3 bucket
3. Set up monitoring (optional: Sentry, DataDog)
4. Configure reverse proxy (Nginx)
5. Set up SSL certificates

---

## ü§ù Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`) 
5. Open a Pull Request

---

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üìû Support

For support and questions:
- Create an issue in this repository
- Email: support@example.com
- Documentation: [Wiki](https://github.com/tojinguyen/Python-AI-Document-Processing/wiki)

---

## üó∫Ô∏è Roadmap

### **Phase 1 (Current)**
- ‚úÖ User authentication system
- ‚úÖ Document upload and storage
- ‚úÖ Basic text extraction and chunking
- ‚úÖ Simple chat interface

### **Phase 2 (Next)**
- üîÑ Advanced embedding models
- üîÑ Improved chat UI/UX
- üîÑ Admin dashboard
- üîÑ Performance optimizations

### **Phase 3 (Future)**
- üìã Multi-language support
- üìã Advanced analytics
- üìã API rate limiting
- üìã Mobile app integration

---

*Last updated: September 18, 2025*